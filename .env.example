# API Keys
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434

# Cache Configuration
CACHE_DIR=.cache
CACHE_ENABLED=true

# Logging
LOG_LEVEL=INFO
LOG_FILE=llm_bench.log

# Dashboard Configuration
STREAMLIT_SERVER_PORT=8501
STREAMLIT_SERVER_ADDRESS=localhost